---
title: "p8105_hw5_zx2424"
author: "Zhaoqianyu Xiong"
date: "2022-11-16"
output: github_document
---
```{r setup, include=FALSE}
library(tidyverse)
library(p8105.datasets)
library(viridis)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

## Problem 1
Iterate over file names and read in data for each subject and save the results as a new variable full_df.
```{r}
full_df = 
  tibble(
    files = list.files("./data/"),
    path = str_c("./data/", files) ) %>% 
  mutate(data = map(path, read_csv)) %>% 
  unnest(cols = c(data))
```

Tidy the results.
```{r}
tidy_df = 
  full_df %>% 
  mutate(
    files = str_replace(files, ".csv", ""),
    group = str_sub(files, 1, 3)) %>%  
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    values_to = "outcome",
    names_prefix = "week_") %>% 
  mutate(week = as.numeric(week)) %>% 
  select(group, subj = files, week, outcome) 

tidy_df
```

Make a spaghetti plot showing observations on each subject over time. For the control group, their outcomes do not change over time, while the outcomes for experiment group increase over time.
```{r}
tidy_df %>% 
  ggplot(aes(x = week, y = outcome, group = subj, color = group)) + 
  geom_point() + 
  geom_path() + 
  facet_grid(~group)
```

## Problem 2
Import and describe the raw data. 
```{r}
homicide_raw = read_csv("https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv")

homicide_raw
```
The dataset contains `r nrow(homicide_raw)` rows and `r ncol(homicide_raw)` columns, with each row representing a homicide case. Variables include reported date, first and last name of the victims, race, age and sex of victims, the city and state where they happened, the exact location of the homicides, the disposition of the cases.

Create a city_state variable.
```{r}
homicide = 
  homicide_raw %>%
  janitor::clean_names() %>%
  mutate(city_state = str_c(city, sep = ",", state)) %>%
  mutate(status = ifelse(disposition == "Closed by arrest", "0", "1")) %>%
  mutate(status = as.integer(status)) 
```

Summarize within cities to obtain the total number of homicides and the number of unsolved homicides.
```{r}
homicide_nest = 
  homicide %>%
  select(city_state, status) %>%
  nest(data = status)

total_and_unsolved = 
  function(df){
    total_df = as.integer(count(df))
    unsolved_df = sum(df)
    
    tibble(total = total_df,
         unsolved = unsolved_df)
  }

n_total_unsolved = 
  homicide_nest %>%
  mutate(model1 = map(homicide_nest$data, total_and_unsolved)) %>%
  unnest(model1) %>%
  select(-data)

n_total_unsolved
```

Estimate the proportion of unsolved homicides for Baltimore, MD.
```{r}
output_Baltimore = 
prop.test(x = n_total_unsolved$unsolved[3], n = n_total_unsolved$total[3]) %>%
  broom::tidy() %>%
  select(estimate, starts_with("conf"))

output_Baltimore 
```

Write a function that can generate the results -- estimated proportion and confidence interval.
```{r}
p_and_CI =
  function(x, n) {
     prop.test(x, n) %>%
      broom::tidy() %>%
      select(estimate, starts_with("conf"))
  }
```

Create a tidy dataframe with estimated proportions and CIs for each city.
```{r}
prop_df = 
n_total_unsolved %>%
  mutate(model2 = map2(.x = unsolved, .y = total, ~p_and_CI(x = .x, n = .y))) %>%
  unnest(model2) %>%
  select(-total, -unsolved)

prop_df
```

Create a plot that shows the estimated unsolved homicide proportions and CIs for each city.
```{r}
 prop_df %>%
  mutate(city_state = fct_reorder(city_state, estimate)) %>%
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
  labs(title = "Estimates and CI for each city",
       x = "City, State",
       y = "Estimate proportions (with CI)") 
```

## Problem 3
Write a function to get estimate and p.value of the sample.
```{r}
sim_mean_p = function(n = 30, mu = 0, sigma = 5){
  sim_data = tibble(
    x = rnorm(n, mean = mu, sd = sigma),
  )
  t.test(sim_data) %>%
    broom::tidy() %>%
    select(estimate, p.value)
}
```

Generate 5000 datasets for $\mu=0$ and save $\hat{\mu}$ (estimate) and p.value.
```{r}
sim_results_df = 
expand.grid(
    sample_size = 30,
    iter = 1:5000
  ) %>%
  mutate(
    estimate_df = map(sample_size, sim_mean_p)
  ) %>%
  unnest(estimate_df)

sim_results_df
```

Repeat the above for $\mu = \{1, 2, 3, 4, 5, 6\}$.
```{r}
sim_df = 
  expand.grid(
    sample_size = 30,
    true_mean = c(1, 2, 3, 4, 5, 6),
    iter = 1:5000
  ) %>%
  mutate(
    estimate_df = map2(.x = sample_size, .y = true_mean, ~sim_mean_p(n = .x, mu = .y))
  ) %>%
  unnest(estimate_df) 
```

Make a plot showing the proportion of times the null was rejected. It can be seen that the further the true_mean is away from 0, the higher is its power.
```{r}
nest_sim_df = 
sim_df %>%
  select(-sample_size, -iter) %>%
  nest(data = estimate:p.value)

test_power = 
  function(df){
    n_reject_df = df %>%
      filter(p.value < 0.05) %>%
      count()
    n_reject = as.integer(n_reject_df)
    power = n_reject/5000
    power
    }

power_mean = 
  nest_sim_df %>%
  mutate(power = map(nest_sim_df$data, test_power)) %>%
  unnest(power) %>%
  select(-data)

power_mean %>%
  ggplot(aes(x = true_mean, y = power)) +
  geom_point() +
  geom_smooth()
```

Make a plot showing the average estimate of mean.
```{r}
average_estimate = 
  function(df){
    mean_estimate = mean(df[["estimate"]])
    mean_estimate
  }

nest_sim_df %>%
  mutate(mu_estimate = map(nest_sim_df$data, average_estimate)) %>%
  unnest(mu_estimate) %>%
  ggplot(aes(x = true_mean, y = mu_estimate)) +
  geom_point() +
  geom_line()
```

Make a second plot showing the average estimate of mean only in samples for which the null was rejected.
```{r}
reject_df = 
  sim_df %>%
  filter(p.value < 0.05) %>%
  select(-sample_size, -iter, -p.value) %>%
  nest(data = (estimate))

reject_df %>%
  mutate(mu_estimate = map(reject_df$data, average_estimate)) %>%
  unnest(mu_estimate) %>%
  ggplot(aes(x = true_mean, y = mu_estimate)) +
  geom_point() +
  geom_line()
```

From two plots, we can see that the sample average estimate of mean only in samples for which the null was rejected not approximately equal to the true value of mean. Because the samples deleted are only in one direction, that means their estimate mean is smaller than true mean. But the ones that have higher value of estimate mean are reserved. So especially for those whose true mean are close to 0, the sample average estimate of mean only in samples for which the null was rejected is higher than true mean.

